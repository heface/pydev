MySQL数据库
pandas提供了将数据便捷存入关系型数据库的方法，在新版的pandas中，主要是已sqlalchemy方式与数据建立连接，支持MySQL、Postgresql、Oracle、MS SQLServer、SQLite等主流数据库。本例以MySQL数据库为代表，展示将获取到的股票数据存入数据库的方法,其他类型数据库请参考sqlalchemy官网文档的create_engine部分。

常用参数说明：

name:表名，pandas会自动创建表结构
con：数据库连接，最好是用sqlalchemy创建engine的方式来替代con
flavor:数据库类型 {‘sqlite’, ‘mysql’}, 默认‘sqlite’，如果是engine此项可忽略
schema:指定数据库的schema，默认即可
if_exists:如果表名已存在的处理方式 {‘fail’, ‘replace’, ‘append’},默认‘fail’
index:将pandas的Index作为一列存入数据库，默认是True
index_label:Index的列名
chunksize:分批存入数据库，默认是None，即一次性全部写人数据库
dtype:设定columns在数据库里的数据类型，默认是None
调用方法：

from sqlalchemy import create_engine
import tushare as ts

df = ts.get_tick_data('600848', date='2014-12-22')
engine = create_engine('mysql://user:passwd@127.0.0.1/db_name?charset=utf8')

#存入数据库
df.to_sql('tick_data',engine)

#追加数据到现有表
#df.to_sql('tick_data',engine,if_exists='append')


MongoDB
pandas目前没有提供直接存入MongoDB的方法，不过依然很简单，而且方式很多，用户可根据自身的业务特点选择存储的结构方式。

使用方法：

import pymongo
import json

conn = pymongo.Connection('127.0.0.1', port=27017)
df = ts.get_tick_data('600848',date='2014-12-22')

conn.db.tickdata.insert(json.loads(df.to_json(orient='records')))



HDF5文件
pandas利用PyTables包将数据保存为HDF5格式的文件。需要确认的是，运行时PyTables包的版本需要 >=3.0.0。

常用参数说明：

path_or_buf: 文件路径或者HDFStore对象
key:HDF5中的group标识
mode : 包括 {‘a’追加, ‘w’写入, ‘r’只读, ‘r+’等同于a但文件必须已经存在}, 默认是 ‘a’
format:‘fixed(f)|table(t)’,默认‘fixed’，f适合快速读写，不能追加数据 t适合从文件中查找和选择数据
append: 适用于table(t)模式追加数据，默认Flase
complevel: 压缩级别1-9, 默认0
complib: 压缩类型{‘zlib’, ‘bzip2’, ‘lzo’, ‘blosc’, None}默认None
调用方法：

import tushare as ts

df = ts.get_hist_data('000875')
df.to_hdf('c:/day/hdf.h5','000875')
方法2：

import tushare as ts

df = ts.get_hist_data('000875')
store = HDFStore('c:/day/store.h5')
store['000875'] = df
store.close()